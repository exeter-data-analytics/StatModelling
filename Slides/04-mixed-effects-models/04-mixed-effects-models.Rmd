---
title: "Repeated Measures and Mixed Models in R Workshop"
author: "T. J. McKinley ([t.mckinley@exeter.ac.uk](mailto:t.mckinley@exeter.ac.uk))"
fontsize: 12pt
output: 
    beamer_presentation:
        latex_engine: xelatex
header-includes:
    - \input{header.tex}
---

```{r, include = F}
library(knitr)
knitr::opts_chunk$set(cache = F, echo = T, fig.align = "center", fig.width = 5, fig.height = 5, resize.width = "0.9\\textwidth", resize.height = "0.9\\textwidth", size = "scriptsize")
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
```

## Structure of the workshop

Full (and more comprehensive notes) are provided at:

\bc

[https://exeter-data-analytics.github.io/StatModelling/](https://exeter-data-analytics.github.io/StatModelling/)

\ec

You are encouraged to go through these in more detail outside of the workshop.

Today we will discuss the main concepts, and work through some (although not all) of the examples in **Section 4** of the notes.

I would encourage you to work from the HTML here, but a PDF is available as a link in the HTML notes.

## RStudio server

CLES have kindly offered the use of their RStudio server in case anyone needs it:

\bc

[https://rstudio04.cles.ex.ac.uk](https://rstudio04.cles.ex.ac.uk)

\ec

**Please note that this server is only for use for this workshop, unless you otherwise have permission to use it .**

You will need to log-in using your University log-in details.

## Recap: (General) Linear Models

```{r setup, echo = F, message = F, warning = F}
## read in arguments from command line
args <- commandArgs(trailingOnly = T)

## set colour for plots in R
highcol <- ifelse(length(args) == 0, "#91CDF2", "#4873A5")
lowcol <- "#F4ABAB"
contcol <- "red"

## load libraries
library(pander)
library(RColorBrewer)
library(knitr)
library(tidyverse)

set.seed(10)

## set colours for plots
cols <- c("#F4ABAB", "#91CDF2", "#5AA566", "#A57C42")
```

Assumptions: 

1. A linear model is relevant.
2. Variances are equal across all fitted values. 
3. Errors are normally distributed.
4. Samples collected at random.
5. Errors are **independent**.

Can use F-tests (see Section 4.1.1 of the notes).

## Aside: Null Hypothesis Significance Testing (NHST)
\small
We have not spent much time on significance testing in these workshops. This is because, whilst useful in some circumstances, NHST techniques are frequently misused and misunderstood.

We have added a section in the notes (Section 4.1) explaining the pros-and-cons of NHST.

That being said, there are times when NHST can be useful, particularly if you have a complex system (perhaps with large numbers of explanatory variables), and you wish to produce a more parsimonious model (perhaps because it is easier to interpret). 

## Aside: NHST
\small
Traditionally, if the response variable is Gaussian (normal), then you may have come across two frequently used approaches:

* **F-tests**: based on comparing the residual mean squared error with the regression mean squared error, or
* **Likelihood ratio tests (LRT)**: based on comparing the model deviance between two models.

Both of these cases are exact tests for linear regression with Gaussian errors (but for mixed models these become approximate). 

## Aside: NHST
\small
\gap[-1]
For mixed models things get trickier again, and there is no consensus. A useful quote from the [GLMM FAQ](https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html) is:

> "For special cases that correspond to classical experimental designs (i.e. balanced designs that are nested, split-plot, randomized block, etc.) ... we can show that the null distributions of particular ratios of sums of squares follow an F distribution with known numerator and denominator degrees of freedom (and hence the sampling distributions of particular contrasts are t-distributed with known df). In more complicated situations (unbalanced, GLMMs, crossed random effects, models with temporal or spatial correlation, etc.) it is not in general clear that the null distribution of the computed ratio of sums of squares is really an F distribution, for any choice of denominator degrees of freedom."

## Aside: NHST
\small
See [GLMM FAQ](https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html) for more discussion. A nice description of the types of approaches we can use in different cases can be found at:

\bc

[https://rdrr.io/cran/lme4/man/pvalues.html](https://rdrr.io/cran/lme4/man/pvalues.html)

\ec

I always try to present final model results in terms of effect sizes and confidence intervals where possible (or via predictive plots). If we have large enough sample sizes and not too many variables, then it may well be fine just to fit one model and perform inference from that.

In this workshop we will introduce some common scenarios in which mixed models can be applied, and give examples of model simplification and inference in these cases.

## Recap: linear model

$$
    Y_i = \beta_0 + \beta_1 X_i + \epsilon_i
$$

where $\epsilon_i \sim N\left(0, \sigma^2\right)$ and $\sigma^2$ is **variance**.

In words:

\bc

response ~ intercept + slope $\times$ explanatory + noise

\ec

## Assumptions

**Previously**: used model checks and biological rationale to test linearity, normality and homoscedasticity of **residuals**.

What about **independence of residuals**?

Depends on **experimental design**.

## Independence of errors

\bcols
\bcol{0.48}
Tests of statistical significance require that each experimental unit has the same $\epsilon$, unaffected by and uncorrelated with other residuals (samples are *independent and identically distributed* - i.i.d.).\newline

**But this is often untrue.**

\ecol
\bcol{0.48}

\bc

**Example**: bacterial loads
\gap

\includegraphics[width=0.8\textwidth]{images/EscherichiaColi_NIAID.jpg}
\small
\gap

**Source**: [Wikipedia](https://en.wikipedia.org/wiki/Bacteria)

\ec

\ecol
\ecols

## Blocked experiment: bacterial growth

Bacteria grown in four different media (fixed **treatment** has ***four*** levels).

Only have small growth cabinets:

* Room for four growth jars per cabinet.
* Use five cabinets (**blocks**).
* One **replicate** of **experiment** per cabinet.

Measure ***bacterial growth rate***.

## Blocked experimental design

Recognise natural structuring among experimental units.

Source of error (e.g. cabinet, top/bottom of field, make of car, student identity).

**Absorb** this error by replicating experiment within blocks.

**Partition** the residual deviance.

## Blocked experiment: bacterial growth

\bc

\includegraphics[width = 0.7\textwidth]{images/bacCabinets.pdf}

\ec

## Why use blocks?

Here **treatment** (media) is of interest, but multiple treatments within each block.

We know growth rates will differ between cabinets.

Assume that **relative** growth rates will be similar between treatments in each cabinet.

Use **cabinet** as a **block** to **absorb** experimental noise.

## Analyse it badly

Ignore non-independent residuals (i.e. ignore cabinet effects)

```{r bac, echo = -c(1:3)}
bac <- read.csv("./data/baccabinets.csv", header = T)
bac$media <- factor(bac$media)
bac$cabinet <- factor(bac$cabinet)
bac_lm <- lm(growth ~ media, data = bac)
anova(bac_lm)
```

## Analyse it properly---part I

Put `cabinet` in as a fixed effect.

```{r bacaov}
bac_lm <- lm(growth ~ media + cabinet, data = bac)
anova(update(bac_lm, ~ . - media), bac_lm)
```

It does not make sense to drop `cabinet` here. Why not?

## Aside: the `update()` function
\small
R provides a neat function to help update parts of a model, without having to re-write the full code.

For example, to drop the `media` term from `bac_lm`, we can write^[to permanently update, we would need to save over the original object e.g. \texttt{bac\_lm <- update(bac\_lm, ...)}]
```{r, eval = F}
update(bac_lm, ~ . - media)
```
\gap[-1]
The `~ .` notation means *"everything on the right-hand side of the original formula"*, then the `- media` notation says to remove `media`.

We can also use this in other ways (see the workshop examples).
\gap

## Mixed effects model
\small 
This simple **balanced** design can be analysed in a straightforward way here, however in general we may have more complex error structures, unbalanced designs and/or potentially many blocks of different structures.

We ideally want a general framework that **accounts** for the variations due to the **blocks**, but models the effect we're interested in: here the effect of **media** on **bacterial growth**. Furthermore, we don't want to use up too many degrees-of-freedom.

These challenges can be dealt with using **mixed models**.

A **mixed model** is so-called because it contains a mixture of **fixed** and **random** effects.

## Fixed effects

* Treatments are **fixed** by the experimenter, guided by **hypotheses** e.g. test of whether treatment levels **differ** or whether there is a **trend**.
* We **care** about the **identity** of each level of a fixed effect.
* Given a new experimental unit, we could predict its response.

## Random effects

* Are sampled from a **population** of possible levels.
* We don't **care** about the **identity** of each level of a random effect^[traditional view, but in some cases we can use REs [differently](http://www.stat.columbia.edu/~gelman/research/published/multiple2f.pdf)].
* Wouldn't help us predict new values of response variable.
* Instead we **predict** how much variance is absorbed by random effects.
* Observations influenced by random effects are **not independent**.

\gap

## A mixed-effects model
\small
\gap[-1]
Response variable $Y$. Regression parameters for **fixed** explanatory variables: $\beta_p$

Noise absorbed by **random variable(s)**: $\gamma \sim N\left(0, \sigma^2_{\gamma}\right)$

Residual noise: $\epsilon \sim N\left(0, \sigma^2\right)$
$$
    Y_i = \beta_0 + \beta_1 X_i + \gamma_i + \epsilon_i
$$

Here $\sigma^2_{\gamma}$ is the **variance** attributed to the random effect, and $\sigma^2$ is the **residual** variance.

This particular model known as a **random intercepts** model.

## What does it do?

\bcols
\bcol{0.48}

**Fixed intercepts**

\ecol
\bcol{0.48}

**Random intercepts**

\ecol
\ecols

\includegraphics[width = 0.9\textwidth]{images/compint.png}

## Analyse it properly---part II

Since we do not care about the impact of `cabinet` *per se*, we could also include this as a **random effect**, using `lmer()`:
```{r, message = F, warning = F, echo = -c(1, 3)}
library(lme4)
bac_lmer <- lmer(growth ~ media + (1 | cabinet), data = bac)
bac_lmer
```
\gap[-1]

## Analyse it properly---part II

Since these data are **balanced**, and the error structure is Gaussian, we are safe to ask for an F-test here to assess what happens when `media` is dropped from the model^[we need to use the `Anova()` function in the `car` package to do this, in the workshop we will see other approaches]
```{r, message = F, warning = F, echo = -1}
library(car)
Anova(bac_lmer, test = "F")
```

## Aside: Restricted Maximum Likelihood

Mixed models fitted using **Restricted Maximum Likelihood (REML)**.

Only possible thanks to powerful computers (fits models iteratively). Separates the influences of random and fixed effects, meanwhile retaining the nested structure of the dataset.

Caveats: 

1. Need good understanding of data structure. 
2. Need to be careful during model simplification. 

## Aside: Simplifying REML models

Be very careful! Standard partitioning of deviance no longer applies. In **balanced, nested** designs, F-tests are OK. For **unbalanced** or **non-nested** designs we have to be more careful.

In these latter cases we need to refit the model using **unrestricted maximum likelihood (ML)**. This produces a **biased** approximation, but usually a good one.

We can do this using `update()` but with a `REML = F` argument. 

After model simplification, switch back to REML fit to perform inference. See **Section 4.2.1.1** of the notes for more details.

## Your turn

Have a go at **Section 4.2** of the workshop notes.

## Nested errors

\bcols
\bcol{0.48}

The previous example was fairly simple. Certain study designs will end up with replicates **nested** with other variables / blocks.
\gap

In this case the residuals are **not independent** once again, but the error structure is more complex to model.

\ecol
\bcol{0.48}

\bc

**Example**: drunken behaviour on campus
\gap

\includegraphics[width=\textwidth]{images/withnail.png}

\ec

\ecol
\ecols

## Nested Errors: Example

\bcols
\bcol{0.48}

Dave got arrested for being disorderly.\newline

He failed a breathaliser test.\newline

To avoid the fine, he claimed he had used breath freshener.\newline

To prove his innocence he conducted an experiment.

\ecol
\bcol{0.48}

\includegraphics[width = \textwidth]{images/vyvyan-0.png}

\ecol
\ecols

## Samples

\bc

\includegraphics[width = 0.8\textwidth]{images/drunkdesign.png}

\ec

## Results
\gap[-3]

```{r drunkres, echo = F, fig.width = 8, fig.height = 8, resize.width = "0.7\\textwidth", resize.height = "0.7\\textwidth"}
drunk <- read.csv("./data/blood_alcohol.csv", header = T)
stripchart(alcohol ~ sample * student, data = drunk, subset = (freshener == "no"), vertical = T, 
           pch = 16, method = "jitter", jitter = 0.2,
           ylab = "Alcohol content", xlab = "", xaxt = "n", col = cols[1], ylim = range(drunk$alcohol), xlim = c(0, 24))
stripchart(alcohol ~ sample * student, data = drunk, subset = (freshener == "yes"), vertical = T, 
           pch = 16, method = "jitter", jitter = 0.2, add = T, col = cols[2])
axis(1, at = 1:24, labels = rep(1:4, times = 6))
for(i in 1:length(levels(drunk$student))) abline(v = (i - 1) * 4 + 0.5, lty = 2)
for(i in 1:length(levels(drunk$student))) mtext(levels(drunk$student)[i], 1, line = 2.5, at = (i - 1) * 4 + 2.5)
legend(1, 0.12, col = cols[1:2], pch = rep(16, 2), legend = paste("Freshener:", levels(drunk$freshener)), bg = "white")
```

## The wrong way!

```{r drunk, echo = -1, message = F}
drunk <- read_csv("./data/blood_alcohol.csv")
drunk_lm <- lm(alcohol ~ freshener, data = drunk)
anova(drunk_lm, test = "F")
```

## What's wrong?

* Multiple samples per student.
* Multiple estimates per sample.
* **Clue**: residual df (`r anova(drunk_lm)$Df[2]`) is much bigger than the number of ***experimental units*** (students: `r length(unique(drunk$student))` here).
* Samples within students are **PSEUDOREPLICATES**.
* Residuals are **not independent**.

## Correct (traditional) analysis

**Derived variable analysis**: 

* Cope with **pseudoreplication** by **averaging** them out.
* Gives one average per student.
* Analyse this smaller dataset.
* **Note**: loses information on **within-student variation**. Could be important if complicated nested experimental design.

## Derived variables in R

I'm using `tidyverse` here, but base R versions are in the workshop notes.

```{r}
alc <- drunk %>%
    group_by(student, freshener) %>%
    summarise(alcohol = mean(alcohol)) %>%
    ungroup()
alc
```

## Derived variables in R

Because I'm only dropping a single variable, I'm safe to use the `anova()` function.

```{r}
alc_lm <- lm(alcohol ~ freshener, data = alc)
anova(alc_lm, test = "F")
```

## Derived variables in R

This is a statistically valid analysis, however:

* it ignores the uncertainties around the pseudo-replicates;
* the interpretation of the response variable is actually the mean of a bunch of measurements, not the measurements themselves. 

In balanced designs this is OK, but it may not be possible to generate derived variables for some studies (how do you average a categorical response for example)?

## Mixed effects model

We ideally want a general purpose way to build a model that **accounts** for the variation due to the **pseudoreplicates**, but models the effect we're interested in: here the effect of **breath freshener** on **alcohol content**.

Again, this can be done with a **mixed model**.

## Mixed model

\bcols
\bcol{0.6}

```{r}
drunk
```

\ecol
\bcol{0.4}
What is:

* The **response**?
* The **fixed** effect(s)?
* The **random** effect(s)?

\ecol
\ecols

## Mixed model

Here we have **samples** *nested* within **students**, with `freshener` as our **fixed** effect.

```{r, echo = F, message = F}
drunk_lmer <- lmer(alcohol ~ freshener + (1 | student / sample), data = drunk)
Anova(drunk_lmer, test = "F")
```

The F-test here gives the same result as the **derived variable** analysis, since the data are **balanced** and **nested**.

## Aside: did Dave drink alcohol?

Suggests negligible difference between blood alcohol content between treatments, given the other uncertainties in the system.

However, does not answer the specific question:

> What is the probability of testing positive given that you've used breath freshener, relative to drinking alcohol^[can be tackled using Bayesian methods]?

Beware of **proxy** measurements (and [prosecutor's fallacy](https://en.wikipedia.org/wiki/Prosecutor%27s_fallacy)).

## Your turn

Have a go at **Section 4.3** in the workshop notes.

## Think about your hypothesis

Tight link between hypothesis, experimental design and analysis.
\gap

\bcols
\bcol{0.48}

Hypothesis defines the experimental unit:

* e.g. "Fire regulates savannah grass diversity"

\ecol
\bcol{0.48}

\includegraphics[width = 0.8\textwidth]{images/savannahfire.png}

\ecol
\ecols

Response is **grass diversity**, and treatment is **burned** vs. **unburned**.

Experimental unit is **plot**.

## Think about your hypothesis

What needs to be replicated?

* Burning treatment.

If only one burn, then there is no replication.

Multiple measures of each burned/unburned plot is **pseudoreplication**.

Good to improve estimate of mean, but still need replication.

Statistical tests must occur at the level of the **experimental unit**.

## Getting more complicated

**Split-plot** experimental design:

* The basis of many agricultural studies.
* Many treatments, spatial non-independence.

**Nested analyses**:

* Study of **variance** at nested scales.
* Common in population genetics.

## Getting more complicated

**Longitudinal studies:**

* Multiple observations of experimental units

Make sure you know what the experimental unit is.

## Example: split-plot design

This experiment involves the yield of cereals in a factorial experiment with:

* 4 **blocks** (fields). 
* Half of each block was **irrigated**, and half not. 
* Each half-block was split into 3 split-plots, and seeds were sown at different **densities** in each split-plot. 
* Each sowing density plot was split into 3 small split-split plots and different **fertilisers** applied by hand (N alone, P alone and N + P together).

## Example: split-plot design

\bc

\includegraphics[width = 0.8\textwidth]{images/splitBlock.png}

\ec

## Example: split-plot design

\bc

\includegraphics[width = 0.8\textwidth]{images/splitBlockIrr.png}

\ec

## Example: split-plot design

\bc

\includegraphics[width = 0.8\textwidth]{images/splitBlockIrrDens.png}

\ec

## Example: split-plot design

\bc

\includegraphics[width = 0.5\textwidth]{images/splitBlockIrrDensFert.png}

\ec

## Example: split-plot design

\gap[-1]

\bc

\includegraphics[width = 0.7\textwidth]{images/splitFull.png}

\ec

## Your turn

Have a go at **Section 4.4** in the workshop notes.

## Distance to Kenyan herbivores

\bcols
\bcol{0.48}

`Distance ~ Species`\newline

Big survey (lots of data) but data is clustered among several observer groups.\newline

Non-independent data: `Group.Name` a **random effect**.
 
\ecol
\bcol{0.48}

\includegraphics[width = 0.8\textwidth]{images/kenya.png}

\ecol
\ecols

## Fixed and random effects in Hell's Gate

**Hypothesis**: Distance from road depends on species.

**Caution**: this could be mediated by group size.

Data not independent because contributed by 8 observer groups. Obs. group does not feature in the hypotheses, they:
\gap[-1]

* are sampled from a wider population of MSc students;
* would not help us predict distances for a new set of observer groups;
* would waste 7 d.f. in a traditional analysis;
* hence makes an 'ideal' random effect.

## Data structure
\gap[-1]
```{r hg, echo = F, size = "tiny"}
hg <- read.csv("./data/HG threespecies.csv", header = T)
hg <- hg[sample(1:nrow(hg), nrow(hg), T), ]
as_tibble(hg)
```
\gap[-1]

**Note**: each observer group contributes data. Could we make a **derived variable** per observer group?

* What is 'average species'? 
* What would happen to the precious variation in group size?

## Fitting a mixed effects model

Here data are **unbalanced**.

```{r}
hg %>% group_by(Group.Name, Species) %>% count()
```

Hence must be careful with model simplification.

## Your turn

Have a go at **Section 4.5** in the notes.

## Model checking

You should really check model assumptions as for general LMs/GLMs.

Trickier to do, but some exampes in **Section 4.6** of the workshop notes.

## Non-normal response

But my data isn't normal...

Package `lme4` also includes function `glmer()`:

* which allows use of `family = ""`

So can try non-normal error structures...

...leading to GLMM (***Generalised Linear Mixed Models***).

## Fitting GLMMs

```{r glmer}
hg_glmer <- glmer(Number ~ Species * log(Distance) 
                + (1 | Group.Name), data = hg, family = poisson, 
                    control = glmerControl(optimizer = "bobyqa"))
drop1(hg_glmer, test = "Chisq")
```

**Note**: uses adaptive Gauss-Hermite quadrature approximation of the likelihood to fit the model, not REML.

## GLMMs

Can use `lme4` for:

* Gaussian, Poisson, binomial, binary, gamma error structures,
* and for crossed and nested random effects structures,
* model checks remain important...

Congratulations, you have become **Generalised Linear Mixed Modellers**.

## The dangers of too much R coding

\bc

\includegraphics[width = 0.5\textwidth]{images/blobfish.png}

\ec
